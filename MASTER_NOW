### CHURN MODELING - DATA SCIENCE PROJECT FOR INTRODUCTION TO PROGRAMMING #####
###############################################################################

import numpy as np
import pandas as pd
import random 
import seaborn as sns
import matplotlib.pyplot as plt


###########  DATA PREPROCESSING  ##############################################
###############################################################################


### 1. IMPORTING THE DATASET ##################################################

dataset = pd.read_csv('/Users/fruechtnicht/NOVA/M.Sc_Data_Science_and_Advanced_Analytics/Semester1/IP/Churn_Modelling.csv')


### 2. HANDLING MISSING VALUES ################################################

dataset.isna().any()
dataset.isnull().sum(axis=0)

y = dataset.iloc[:, 13]
X = dataset.iloc[:, :-1]

### 3. FEATURE SELECTION ######################################################

X.columns.values
X.drop(['Surname'], axis=1, inplace=True)
X.drop(['CustomerId'], axis=1, inplace=True)
X.drop(['RowNumber'], axis=1, inplace=True)

### 4. HANDLING ERRORS  ######################################################


#excluding binary variables for boxplots
X_boxplot=X[[i for i in list(X.columns) if i not in ['HasCrCard', 'IsActiveMember']]]

# boxplots for outliers
plt.style.use('ggplot')
X_boxplot.plot(kind='box', subplots=True, layout=(2, 3), sharex = False, sharey=False, figsize=(20,10))
plt.suptitle('Column Boxplots', size=25, color='orange', fontweight='bold')

from pandas.plotting import scatter_matrix
scatter_matrix(dataset)
plt.show()

# histograms for columns of interest
sns.set_style('darkgrid')
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(231)
ax2 = fig.add_subplot(232)
ax3 = fig.add_subplot(233)
ax4 = fig.add_subplot(234)
ax5 = fig.add_subplot(235)
ax6 = fig.add_subplot(236)

sns.distplot(X['CreditScore'], kde=False, color='red', ax=ax1)
sns.distplot(X['Age'], kde=False, color='red', ax=ax2)
sns.distplot(X['Tenure'], kde=False, color='red', ax=ax3)
sns.distplot(X['Balance'], kde=False, color='red', ax=ax4)
sns.distplot(X['NumOfProducts'], kde=False, color='red', ax=ax5)
sns.distplot(X['EstimatedSalary'], kde=False, color='red', ax=ax6)

plt.suptitle('Column Histograms', size=25, color='grey', fontweight='bold')

#log transformation on Age
X['Age']=np.log(X['Age'])

### 5. ENCODING CATEGORICAL VARIABLES #########################################

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelEncoder2 = LabelEncoder() 
X['Gender'] = labelEncoder2.fit_transform(X['Gender'])

degree_dummies=pd.get_dummies(X['Geography'], drop_first=False)
X.drop(['Geography'], axis=1, inplace=True)
X=pd.concat([X, degree_dummies], axis=1)

X = X.apply(pd.to_numeric)
X.info()
### 5. SPLITTING THE DATASET INTO TRAINING SET AND TEST SET ###################

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train_ind = X_train.index.values
X_test_ind = X_test.index.values


## 6 FEATURE STANDARD SCALING #################################################
#   6.1 Standardize features by removing the mean and scaling to unit variance
#    6.1.1 with scaling dummy variables 

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#to df
X_train = pd.DataFrame(data=X_train, index = X_train_ind, columns=list(X.columns.values))
X_test = pd.DataFrame(data=X_test, index = X_test_ind, columns=list(X.columns.values))

#    6.1.1 without scaling dummy variables 

#from sklearn.preprocessing import StandardScaler
#sc_X = StandardScaler()
#X_train[:,3:4] = sc_X.fit_transform(X_train[:,3:4])
#X_test[:,3:4] = sc_X.transform(X_test[:,3:4])
#X_train[:,5:6] = sc_X.fit_transform(X_train[:,5:6])
#X_test[:,5:6] = sc_X.transform(X_test[:,5:6])
#X_train[:,7:9] = sc_X.fit_transform(X_train[:,7:9])
#X_test[:,7:9] = sc_X.transform(X_test[:,7:9])
#X_train[:,11:12] = sc_X.fit_transform(X_train[:,11:12])
#X_test[:,11:12] = sc_X.transform(X_test[:,11:12])

#   6.2 Transforms features by scaling each feature to a given range.

#from sklearn.preprocessing import MinMaxScaler
#
#scaler = MinMaxScaler()
#X_train = scaler.fit_transform(X_train)
#X_test  = scaler.transform(X_test)




###########2  DATA TRANSFORMATION AND VISULIZATION  ###########################
###############################################################################

### 1 BASIC DESCRIPTIVE STATISTICS ############################################ its all on the X is that right ??
import matplotlib.pyplot as plt

X.describe()

dataset.groupby('Exited').size()
benchmark = max(dataset.groupby('Exited').size()[0], dataset.groupby('Exited').size()[0])/(dataset.groupby('Exited').size()[0] + dataset.groupby('Exited').size()[1])

print(pd.DataFrame(y_test).groupby('Exited').size())
print('>>>   Percentage of clients who Exited is : {0:.2%}'.format(y.index.isin(list(y.index[(y == 1 )== True])).sum()/(y.index.isin(list(y.index[(y == 1 )== True] )).sum()+y.index.isin(list(y.index[(y == 1 )== False])).sum())))
print(">>>   Base line accuracy of prediction is {0:.2%}".format(benchmark))
        


#### EXPLORATORY DATA VISUALIZATION#############################################

#Pairplots
train_df = pd.concat([X_train, y_train], axis=1)
       
sns.pairplot(train_df, hue="Exited" , vars = [
                                                'CreditScore'
                                              , 'Gender'
                                              , 'Age'
#                                              , 'Tenure'
#                                              , 'Balance'
#                                              , 'NumOfProducts'
#                                              , 'HasCrCard'
#                                              , 'IsActiveMember'
#                                              , 'EstimatedSalary'
#                                              , 'France'
#                                              , 'Germany'
#                                              , 'Spain'
                                              ]
                                                , diag_kind = "kde")
                                                
#Active vs inactive members exiting
fig, ax =plt.subplots(1,2, sharey=True, sharex=True)
plt.suptitle('Number of Exits among Active and Inactive Members', size=13, color='grey', fontweight='bold')
sns.countplot(dataset[dataset['IsActiveMember']==1]['Exited'], ax=ax[0])
sns.countplot(dataset[dataset['IsActiveMember']==0]['Exited'], ax=ax[1])
ax[0].set_xlabel('Active Members', color='green')
ax[0].set_ylabel(' ')
ax[1].set_xlabel('Inactive Members', color='red')
ax[1].set_ylabel(' ')
#add labels %

#Exits per country
fig, ax =plt.subplots(1,3, sharey=True, sharex=True)
plt.suptitle('Number of Exits per country', size=13, color='grey', fontweight='bold')
sns.countplot(dataset[dataset['Geography']=='Spain']['Exited'], ax=ax[0])
sns.countplot(dataset[dataset['Geography']=='France']['Exited'], ax=ax[1])
sns.countplot(dataset[dataset['Geography']=='Germany']['Exited'], ax=ax[2])
ax[0].set_xlabel('Spain')
ax[0].set_ylabel(' ')
ax[1].set_xlabel('France')
ax[1].set_ylabel(' ')
ax[2].set_xlabel('Germany')
ax[2].set_ylabel(' ')


### 3 CORRELATION #############################################################

pd.options.display.max_columns = 12
pd.set_option('expand_frame_repr', True)
pd.set_option('max_colwidth',30)
#pd.reset_option('^display.', silent=True)
sns.heatmap(X.corr())

###########  MODELING DATASET  ################################################
###############################################################################

####  2. MULTIPLE LINEAR REGRESSION WITH BACKWARD ELIMINATION #################
import statsmodels.formula.api as sm
from sklearn.linear_model import LinearRegression

X_opt = X.copy()
X_train_opt = X_train.copy()
X_test_opt = X_test.copy()
y_train_opt = y_train.copy()

regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt.drop(['HasCrCard'], axis=1, inplace=True)
regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt.drop(['EstimatedSalary'], axis=1, inplace=True)
regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary() 
X_opt.drop(['Tenure'], axis=1, inplace=True)
regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt.drop(['Germany'], axis=1, inplace=True)
regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt.drop(['NumOfProducts'], axis=1, inplace=True)  # Although below the adopted threshold worth to consider deleting this column also
regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()

regressor = LinearRegression()
X_train_opt.drop(['HasCrCard', 'EstimatedSalary', 'Tenure', 'Germany', 'NumOfProducts'], axis=1, inplace=True)
regressor.fit(X_train_opt, y_train_opt)
X_test_opt.drop([ 'HasCrCard', 'EstimatedSalary', 'Tenure', 'Germany', 'NumOfProducts'], axis=1, inplace=True)
y_pred = regressor.predict(X_test_opt)

plt.hist(y_pred)

# Assiging predicted values into decision
for q in range(len(y_pred)):
    if y_pred[q]<0.5: #(max(y_pred) - min(y_pred))/2:
        y_pred[q]=0
    else: y_pred[q] = 1
    
# Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
(cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])

benchmark = max(benchmark, (cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1]))       
print(cm)
print('>>>   Accuracy of this model is : {0:.2%}'.format((cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])))
print('>>>   The investment return when this model is applied is:  €{:0,.2f}'.format(cm[0][0]*0 + cm[1][1]*200 + cm[1][0]*(-140) + cm[0][1]*(-450)).replace('€-','-€'))
print(">>>   Best accuracy of prediction was {0:.2%}".format(benchmark)) 
print(">>>   Current best prediction is {0:.2%}".format(benchmark))        
  

##### 2 PCA & lOGISTIC REGRESSION #############################################

X_pca = X.copy()
X_train_pca = X_train.copy()
X_test_pca = X_test.copy()
y_train_pca = y_train.copy()


from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
X_train_pca = pca.fit_transform(X_train_pca)
X_test_pca = pca.transform(X_test_pca)
explained_variance = pca.explained_variance_ratio_


### 5 Fitting Logistic Regression to the Training set
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state=10)
classifier.fit(X_train_pca, y_train_pca)

# Predict the Test set results
y_pred = classifier.predict(X_test_pca)

# Confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
(cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])

benchmark = max(benchmark, (cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1]))       
print(cm)
print('>>>   Accuracy of this model is : {0:.2%}'.format((cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])))
print('>>>   The investment return when this model is applied is:  €{:0,.2f}'.format(cm[0][0]*0 + cm[1][1]*200 + cm[1][0]*(-140) + cm[0][1]*(-450)).replace('€-','-€'))
print(">>>   Best accuracy of prediction was {0:.2%}".format(benchmark)) 
print(">>>   Current best prediction is {0:.2%}".format(benchmark))        
 

# Visualising the Training set results
#from matplotlib.colors import ListedColormap
#
#X_set, y_set = X_train_pca, y_train_pca
#X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
#                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
#plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
#             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))
#plt.xlim(X1.min(), X1.max())
#plt.ylim(X2.min(), X2.max())
#for i, j in enumerate(np.unique(y_set)):
#    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
#                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)
#plt.title('Logistic Regression (Training set)')
#plt.xlabel('PC1')
#plt.ylabel('PC2')
#plt.legend()
#plt.show()
#
## Visualising the Test set results
#from matplotlib.colors import ListedColormap
#X_set, y_set = X_test_pca, y_test
#X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
#                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
#plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
#             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))
#plt.xlim(X1.min(), X1.max())
#plt.ylim(X2.min(), X2.max())
#for i, j in enumerate(np.unique(y_set)):
#    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
#                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)
#plt.title('Logistic Regression (Test set)')
#plt.xlabel('PC1')
#plt.ylabel('PC2')
#plt.legend()
#plt.show()



#### 3 Decision Tree ###############################

X_tre = X.copy()
X_train_tre = X_train.copy()
X_test_tre = X_test.copy()
y_train_tre = y_train.copy()

from sklearn.tree import DecisionTreeClassifier       #importing the tree
dtree = DecisionTreeClassifier(random_state = 0)                      #setting up a tree
dtree.fit(X_train_tre,y_train_tre)                            #using the train data to train the tree
y_pred = dtree.predict(X_test_tre)                   #making predicitons on the test data
from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
print('Descision Tree')
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)
### in my opinion we should try to focus on predicting true positives and min the type II error -> amining for a sensitivity, hence applying the random forest
## is 1 = potivie and 0 negative ?

#problem it changes everytime i dont know why 


#### random forest ####

X_rf = X.copy()
X_train_rf = X_train.copy()
X_test_rf = X_test.copy()
y_train_rf = y_train.copy()

from sklearn.ensemble import RandomForestClassifier   #omporting the RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=300, random_state=0)        #setting up a RFC with 300 estimators (number of randomly distributed trees classifing the object; default is 100)
rfc.fit(X_train_rf,y_train_rf)                              #using the train data to train the rfc
y_pred = rfc.predict(X_test_rf)                     #making predicitons on the test data
from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
print('Random Forest')
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)
###turns out that type II error increases, the model is wore for us..



# My tree

X_tre = X.copy()
X_train_tre = X_train.copy()
X_test_tre = X_test.copy()
y_train_tre = y_train.copy()

# Fitting Decision Tree Classification to the Training set
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy')
classifier.fit(X_train_tre, y_train_tre)

# Predicting the Test set results
y_pred = classifier.predict(X_test_tre)

# Making the Confusion Matrix
from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
cm = confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))         #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)

### My forrest

X_rf = X.copy()
X_train_rf = X_train.copy()
X_test_rf = X_test.copy()
y_train_rf = y_train.copy()


# Fitting Random Forest Classification to the Training set
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)
classifier.fit(X_train_rf, y_train_rf)

# Predicting the Test set results
y_pred = classifier.predict(X_test_rf)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)


#############################SUPPORT VECTOR MACHINES###########################

X_svm = X.copy()
X_train_svm = X_train.copy()
X_test_svm = X_test.copy()
y_train_svm = y_train.copy()

from sklearn.svm import SVC

svc=SVC(verbose=True, random_state=0)

svc.fit(X_train_svm, y_train_svm)

predictions=svc.predict(X_test_svm)

from sklearn.metrics import confusion_matrix, classification_report

svm_matrix=confusion_matrix(y_test, predictions)

print(svm_matrix)

(svm_matrix[0][0]+svm_matrix[1][1])/(svm_matrix[0][0]+svm_matrix[1][1]+svm_matrix[0][1]+svm_matrix[1][0])

print(classification_report(y_test, predictions))#DOMINIKA: Interpretation

print('>>>   Accuracy of this model is : {0:.2%}'.format((svm_matrix[0][0]+svm_matrix[1][1])/(svm_matrix[0][0]+svm_matrix[1][1]+svm_matrix[0][1]+svm_matrix[1][0])))

from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = svm_matrix.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)


###GRID SEARCH FOR BETTER RESULTS########

from sklearn.model_selection import GridSearchCV

param_grid={'C':[0.1, 1, 10, 100, 1000], 'gamma':[1,0.1,0.01,0.001, 0.0001]}

grid=GridSearchCV(SVC(), param_grid, refit=True, verbose=2)

grid.fit(X_train_svm, y_train_svm)

#Checking best parameters
grid.best_params_

grid_predictions=grid.predict(X_test)

grid_matrix=confusion_matrix(y_test, grid_predictions)

print(grid_matrix)

print(classification_report(y_test, grid_predictions))

(grid_matrix[0][0]+grid_matrix[1][1])/(grid_matrix[0][0]+grid_matrix[1][1]+grid_matrix[0][1]+grid_matrix[1][0])
print('>>>   Accuracy of this model is : {0:.2%}'.format((grid_matrix[0][0]+grid_matrix[1][1])/(grid_matrix[0][0]+grid_matrix[1][1]+grid_matrix[0][1]+grid_matrix[1][0])))

from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)

############################### NAive BAis

import sklearn
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split

from sklearn import metrics
from sklearn.metrics import accuracy_score


#predictions based on binary feautures
BernNB = BernoulliNB (binarize=True)
BernNB.fit(X_train, y_train)
print (BernNB)

predicted_y = BernNB.predict(X_test)
expected_y = y_test
y_pred = BernNB.predict(X_test)
print (accuracy_score(expected_y, predicted_y))

#
#
##good for freauency counts(Example: word count)
#MultiNB = MultinomialNB()
#MultiNB.fit (X_train, y_train)
#print (MultiNB)
#

#print (accuracy_score(expected_y, predicted_y))
#
#
#
#
##good for normally distributed features
#GausNB = GaussianNB()
#GausNB.fit(X_train, y_train)
#print (GausNB)
#
#predicted_y = GausNB.predict(X_test)
#print (accuracy_sc0e(expected_y, predicted_y))


from sklearn.metrics import classification_report,confusion_matrix#importing reporting methods
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)          #printing the confusion matrix 
print(cm)
tn, fp, fn, tp = cm.ravel()
sen = tp/(tp + fn)
print('True positive  = ', tp)
print('False positive = ', fp)
print('False negative = ', fn)
print('True negative  = ', tn)
print('Sensitivity  = ', sen)

print('>>>   Accuracy of this model is : {0:.2%}'.format((cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])))
print(">>>   Best accuracy of prediction was {0:.2%}".format(benchmark)) 
print(">>>   Current best prediction is {0:.2%}".format(benchmark))        


#### 3 SINGLE LAYER NEURAL NETWORL - PERCEPTRON ###############################

X_ann = X.copy()
X_train_ann = X_train.copy()
X_test_ann = X_test.copy()
y_train_ann = y_train.copy()


class NeuralNetwork():
    
    def __init__(self):
        np.random.seed(4)
        self.synaptic_weights = 2 * np.random.random((12,1)) -1
        
    def sigmoid(self, x):
        return 1/ (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1-x)
    
    def train(self, training_inputs, training_outputs, training_iterations):
        
        for interation in range(training_iterations):
            output = self.think(training_inputs)
            error = training_outputs - output
            adjustment = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))
            #self.synaptic_weights = self.synaptic_weights + adjustment
            self.synaptic_weights += adjustment
            
    def think(self, inputs):
        inputs = inputs.astype(float)
        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))
        return output

y_train_ann = pd.DataFrame(y_train_ann)
neural_network = NeuralNetwork()  
training_inputs = np.array([list(l) for l in X_train_ann])
training_outputs = np.array(list(np.array([list(a) for a in y_train_ann.values]).T.tolist())).T
neural_network.train(training_inputs, training_outputs, 100000)
print("Ending Weights After Training: ")
print(neural_network.synaptic_weights)

y_pred = []
for i in range(len(X_test_ann)):
    y_pred.append( neural_network.think(X_test_ann[i]))

for q in range(len(y_pred)):
    if y_pred[q]<0.50:
        y_pred[q]=0
    else: y_pred[q] = 1

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
(cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])

benchmark = max(benchmark, (cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1]))       
print(cm)
print('>>>   Accuracy of this model is : {0:.2%}'.format((cm[0][0] + cm[1][1] )/ (cm[0][0] + cm[1][1] + cm[1][0] + cm[0][1])))
print(">>>   Best accuracy of prediction was {0:.2%}".format(benchmark)) 
print(">>>   Current best prediction is {0:.2%}".format(benchmark))        


